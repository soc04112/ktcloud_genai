{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNkuxQaDMBt5"
   },
   "source": [
    "# **VSC 에서 OpenAI Whisper 사용하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXv9kLODMMLI"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vCdKDfUM9Lw"
   },
   "source": [
    "- 💡 **NOTE**\n",
    "    - 이 과정은 PC Visual Studio Code(이하 VSC)에서 진행합니다.\n",
    "    - 가상환경 생성과 라이브러리 설치는 VSC 터미널에서 진행합니다.\n",
    "    - 아래 내용은 Windows PC 환경을 가정하여 설명되었습니다.    \n",
    "    - 참고 : https://bcuts.tistory.com/192\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kfq1gfmZOAnr"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPcm74RoEnQ2"
   },
   "source": [
    "## **Whisper 소개**\n",
    "- Whisper는 OpenAI가 개발한 자동 음성 인식(ASR: Automatic Speech Recognition) 시스템\n",
    "- 2022년 9월 OpenAI에 의해 처음 공개한 오픈 소스 모델\n",
    "- 인터넷에서 수집한 방대한 양의 오디오 데이터로 훈련되어, 다양한 언어와 악센트, 배경 소음 속에서도 매우 뛰어난 정확도를 자랑함\n",
    "- 기존의 음성 인식 모델들이 가진 한계를 극복하고, 음성-텍스트 변환과 언어 번역을 동시에 수행할 수 있도록 설계된 혁신적인 모델\n",
    "- 대규모 약한 지도 학습(Large-Scale Weak Supervision)\"이라는 독특한 방식을 사용\n",
    "    - Whisper는 인터넷에서 수집한 방대한 양의 오디오와 해당 오디오의 전사본으로 학습\n",
    "    - 이 데이터들은 유튜브 영상의 자동 생성 자막처럼 정확도가 완벽하지는 않지만, 양이 엄청나게 많다는 특징을 가짐\n",
    "    - 대량의 \"약한\" 데이터로 학습함으로써, Whisper는 다양한 언어, 배경 소음, 억양 등 현실 세계의 복잡한 음성 환경에 대한 높은 일반화 능력을 갖추게 됨\n",
    "\n",
    "- transcribe : 음성 인식\n",
    "    > model.transcribe(audio, fp16=False)\n",
    "- translate : 번역  \n",
    "    > model.translate(audio, fp16=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYTyJdATEnQ2"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpNGL4AxMa0E"
   },
   "source": [
    "## **설치 순서(Windows)**\n",
    "\n",
    "1. 가상환경 생성 (권장)\n",
    "2. PyTorch 설치\n",
    "3. Whisper 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EttpKVxoMzX5"
   },
   "source": [
    "### **1.가상환경 생성 (권장)**\n",
    "터미널에서 실행한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ah_OTgncOYCw"
   },
   "outputs": [],
   "source": [
    "python -m venv whisper-env\n",
    "whisper-env\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7zqLLdUPY-7"
   },
   "source": [
    "- **만약 보안 오류가 발생한 경우(UnauthorizedAccess)**\n",
    "- 해결 방법(영구해결)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDlhyXYaEnQ4"
   },
   "source": [
    "1) VS Code 터미널(파워셸)에서 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyJDER2BEnQ5"
   },
   "outputs": [],
   "source": [
    "# 터미널에서 실행한다.\n",
    "Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy RemoteSigned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeMZdkJbEnQ5"
   },
   "source": [
    "2) 새 터미널을 열고 가상환경 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrccFwvNEnQ5"
   },
   "outputs": [],
   "source": [
    "# 터미널에서 실행한다.\n",
    ".\\whisper-env\\Scripts\\Activate.ps1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_q3gcpR_EnQ5"
   },
   "source": [
    "3) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OggqmOoEnQ5"
   },
   "outputs": [],
   "source": [
    "# 터미널에서 실행한다.\n",
    "python -c \"import sys; print(sys.executable); print(sys.version)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vt1O4MtgMzff"
   },
   "source": [
    "### **2.PyTorch 설치**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tjxo7oBvOD5M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python\\python313\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\python\\python313\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\python\\python313\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\python\\python313\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python\\python313\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\python\\python313\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\python\\python313\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\python\\python313\\lib\\site-packages (from torchvision) (2.3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\python\\python313\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzFX1uv9Mznk"
   },
   "source": [
    "### **3.Whisper 설치**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aywVF71vOERd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\user\\appdata\\local\\temp\\pip-req-build-lq51dhdd\n",
      "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: more-itertools in c:\\python\\python313\\lib\\site-packages (from openai-whisper==20250625) (10.8.0)\n",
      "Requirement already satisfied: numba in c:\\python\\python313\\lib\\site-packages (from openai-whisper==20250625) (0.62.0)\n",
      "Requirement already satisfied: numpy in c:\\python\\python313\\lib\\site-packages (from openai-whisper==20250625) (2.3.3)\n",
      "Requirement already satisfied: tiktoken in c:\\python\\python313\\lib\\site-packages (from openai-whisper==20250625) (0.11.0)\n",
      "Requirement already satisfied: torch in c:\\python\\python313\\lib\\site-packages (from openai-whisper==20250625) (2.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\python\\python313\\lib\\site-packages (from openai-whisper==20250625) (4.67.1)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\python\\python313\\lib\\site-packages (from numba->openai-whisper==20250625) (0.45.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\python\\python313\\lib\\site-packages (from tiktoken->openai-whisper==20250625) (2025.9.18)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\python\\python313\\lib\\site-packages (from tiktoken->openai-whisper==20250625) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.8.3)\n",
      "Requirement already satisfied: filelock in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch->openai-whisper==20250625) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python\\python313\\lib\\site-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\python\\python313\\lib\\site-packages (from tqdm->openai-whisper==20250625) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-req-build-lq51dhdd'\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLykieF9EnQ6"
   },
   "source": [
    "### **4.ffmpeg 설치**\n",
    "- 참고 : https://angelplayer.tistory.com/351\n",
    "- https://ffmpeg.org/  \n",
    "- 다운로드 > 윈도우 버튼 >(Windows EXE Files) Windows builds from gyan.dev 선택\n",
    "- ffmpeg-git-full.7z 선택 > 압축풀고 > 폴더 이름을 ffmpeg 으로 변경한다.\n",
    "- ffmpeg 폴더 전체를 C:\\로 이동시키고\n",
    "- 고급 시스템 설정 > 환경변수 > 시스템 변수 > Path에 추가한다. (C:\\ffmpeg\\bin)\n",
    "- 꼭!!! VSC 재시작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gxVJoTioEnQ6",
    "outputId": "ff8659bd-1dcc-4b65-fbb8-7ebfbd32b2aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ CWD: c:\\python\\ktcloud\\ktcloud_genai\n",
      "▶ Audio Path: C:\\python\\ktcloud\\ktcloud_genai\\audio\\오디오-슬라이드2.mp3\n",
      "▶ Audio Exists?: True\n",
      "▶ ffmpeg on PATH?: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "▶ ffprobe on PATH?: C:\\ffmpeg\\bin\\ffprobe.EXE\n"
     ]
    }
   ],
   "source": [
    "# 사전 점검 코드\n",
    "from pathlib import Path\n",
    "import shutil, sys\n",
    "\n",
    "audio = Path(r\"./audio/오디오-슬라이드2.mp3\")  # 필요시 절대경로로 바꾸세요\n",
    "print(\"▶ CWD:\", Path.cwd())\n",
    "print(\"▶ Audio Path:\", audio.resolve())\n",
    "print(\"▶ Audio Exists?:\", audio.exists())\n",
    "print(\"▶ ffmpeg on PATH?:\", shutil.which(\"ffmpeg\"))\n",
    "print(\"▶ ffprobe on PATH?:\", shutil.which(\"ffprobe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPadLTQUEnQ6"
   },
   "outputs": [],
   "source": [
    "# - 터미널에서 실행\n",
    "$env:Path = \"C:\\ffmpeg\\bin;\" + $env:Path\n",
    "ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pKMISxcdEnQ6",
    "outputId": "290cbdc4-2352-419b-f9f5-2d024df27cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\python\\ktcloud\\ktcloud_genai\n",
      "Rel exists?: True\n",
      "Abs exists?: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"Rel exists?:\", Path(\"./audio/오디오-슬라이드2.mp3\").exists())\n",
    "print(\"Abs exists?:\", Path(r\"C:\\python\\ktcloud\\ktcloud_genai\\audio\\오디오-슬라이드2.mp3\").exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3AetcpfRSd3"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyLeDgtBRTlz"
   },
   "source": [
    "## **Whisper로 음성 파일을 텍스트로 변환하기**\n",
    "\n",
    "1. Whisper 라이브러리 불러오기\n",
    "2. 모델 로드하기\n",
    "3. 음성 파일을 읽어들여 변환\n",
    "4. 결과 출력 또는 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbRJiHnbEnQ7"
   },
   "source": [
    "- 영어 오디오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "2MBQh_HwR5-Z",
    "outputId": "591b45d5-a723-4a7a-969d-33c038e895e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pay attention to me.\n"
     ]
    }
   ],
   "source": [
    "# 1.Whisper 라이브러리 불러오기\n",
    "import whisper\n",
    "\n",
    "# 2.모델 로드하기\n",
    "model = whisper.load_model(\"small\")  # tiny, base, small, medium, large\n",
    "\n",
    "# 3.음성 파일을 읽어들여 변환 .wav, .mp3, .m4a, .webm, .ogg, .flac 등\n",
    "audio = r\"C:\\python\\ktcloud\\ktcloud_genai\\audio\\아동-영어1.wav\"\n",
    "result = model.transcribe(audio, fp16=False)  # fp16=False 옵션은 CPU 환경에서 필요\n",
    "print(result[\"text\"])\n",
    "\n",
    "\n",
    "# 4.결과 출력 또는 저장\n",
    "with open(\"output_eng.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxR68TacEnQ7"
   },
   "source": [
    "- 한글 오디오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NiyhvUZbEnQ7",
    "outputId": "08ce66b3-ae9e-44ee-9378-b026bbe82e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 커피의 맛을 이해하기 위해서는 4가지 주요 요소를 살펴보는 것이 중요합니다. 첫째, 삼미는 심맛의 강도를 나타내며 이는 과일이나 로스팅 과정에서 기인합니다. 둘째, 바디감은 커피가 입 안에서 느껴지는 묵직함과 질감을 의미하며 커피의 무게감을 표현합니다.\n",
      "저장 완료: output_kor.txt\n"
     ]
    }
   ],
   "source": [
    "import whisper, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "audio_path = Path(r\"C:\\python\\ktcloud\\ktcloud_genai\\audio\\오디오-슬라이드2.mp3\")  # 절대경로 권장\n",
    "\n",
    "\n",
    "# 1) 필수 전제 확인\n",
    "assert audio_path.exists(), f\"오디오 파일이 없습니다: {audio_path}\"\n",
    "assert shutil.which(\"ffmpeg\"), \"ffmpeg를 찾을 수 없습니다. 설치 후 PATH에 등록하세요.\"\n",
    "assert shutil.which(\"ffprobe\"), \"ffprobe를 찾을 수 없습니다. ffmpeg 설치 시 함께 등록됩니다.\"\n",
    "\n",
    "\n",
    "# 2) 모델 로드 (CPU 사용 시 fp16 비활성화 권장)\n",
    "model = whisper.load_model(\"small\")   # tiny/base/small/medium/large\n",
    "result = model.transcribe(str(audio_path), fp16=False)  # CPU면 fp16=False로 경고 억제\n",
    "print(result[\"text\"])\n",
    "\n",
    "\n",
    "# 3) 저장\n",
    "Path(\"output_kor.txt\").write_text(result[\"text\"], encoding=\"utf-8\")\n",
    "print(\"저장 완료: output_kor.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVHXkFjiEnQ7"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL_d48R8Rjq0"
   },
   "source": [
    "## **실시간 음성 인식**\n",
    "\n",
    "- 참고 : https://bcuts.tistory.com/197\n",
    "\n",
    "- 반복 과정\n",
    "    - 마이크로부터 5초간 음성\n",
    "    - 입력 데이터를 .wav 파일로 저장\n",
    "    - 저장된 파일을 Whisper로 처리\n",
    "    - 텍스트 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6J67aq1gEnQ7"
   },
   "source": [
    "### 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tZVhNEJqEnQ7",
    "outputId": "181d8446-9a03-4e71-8e7d-b7198280b22f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\python\\python313\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: numpy in c:\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: soundfile in c:\\python\\python313\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\python\\python313\\lib\\site-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\python\\python313\\lib\\site-packages (from cffi>=1.0->soundfile) (2.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio numpy soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBJXlKdJEnQ8"
   },
   "source": [
    "### 실시간 음성인식 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5FR0RGINEnQ8",
    "outputId": "5f7e0e54-4cbe-4c5c-d668-bd36768d1c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실시간 음성 인식 시작 (Ctrl+C로 종료)\n",
      "📢 인식된 텍스트: \n",
      "📢 인식된 텍스트:  점순의 먹은 라면은 맛있었다\n",
      "종료합니다.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"temp.wav\"\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "stream = audio.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"실시간 음성 인식 시작 (Ctrl+C로 종료)\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = []\n",
    "        for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "        wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "        wf.close()\n",
    "\n",
    "        result = model.transcribe(WAVE_OUTPUT_FILENAME)\n",
    "        print(\"📢 인식된 텍스트:\", result[\"text\"])\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"종료합니다.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mNIgtqgEnQ8"
   },
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
