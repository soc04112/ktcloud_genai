{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNkuxQaDMBt5"
   },
   "source": [
    "# **VSC ì—ì„œ OpenAI Whisper ì‚¬ìš©í•˜ê¸°**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXv9kLODMMLI"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vCdKDfUM9Lw"
   },
   "source": [
    "- ğŸ’¡ **NOTE**\n",
    "    - ì´ ê³¼ì •ì€ PC Visual Studio Code(ì´í•˜ VSC)ì—ì„œ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "    - ê°€ìƒí™˜ê²½ ìƒì„±ê³¼ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ëŠ” VSC í„°ë¯¸ë„ì—ì„œ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "    - ì•„ë˜ ë‚´ìš©ì€ Windows PC í™˜ê²½ì„ ê°€ì •í•˜ì—¬ ì„¤ëª…ë˜ì—ˆìŠµë‹ˆë‹¤.    \n",
    "    - ì°¸ê³  : https://bcuts.tistory.com/192\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kfq1gfmZOAnr"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPcm74RoEnQ2"
   },
   "source": [
    "## **Whisper ì†Œê°œ**\n",
    "- WhisperëŠ” OpenAIê°€ ê°œë°œí•œ ìë™ ìŒì„± ì¸ì‹(ASR: Automatic Speech Recognition) ì‹œìŠ¤í…œ\n",
    "- 2022ë…„ 9ì›” OpenAIì— ì˜í•´ ì²˜ìŒ ê³µê°œí•œ ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë¸\n",
    "- ì¸í„°ë„·ì—ì„œ ìˆ˜ì§‘í•œ ë°©ëŒ€í•œ ì–‘ì˜ ì˜¤ë””ì˜¤ ë°ì´í„°ë¡œ í›ˆë ¨ë˜ì–´, ë‹¤ì–‘í•œ ì–¸ì–´ì™€ ì•…ì„¼íŠ¸, ë°°ê²½ ì†ŒìŒ ì†ì—ì„œë„ ë§¤ìš° ë›°ì–´ë‚œ ì •í™•ë„ë¥¼ ìë‘í•¨\n",
    "- ê¸°ì¡´ì˜ ìŒì„± ì¸ì‹ ëª¨ë¸ë“¤ì´ ê°€ì§„ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ , ìŒì„±-í…ìŠ¤íŠ¸ ë³€í™˜ê³¼ ì–¸ì–´ ë²ˆì—­ì„ ë™ì‹œì— ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ í˜ì‹ ì ì¸ ëª¨ë¸\n",
    "- ëŒ€ê·œëª¨ ì•½í•œ ì§€ë„ í•™ìŠµ(Large-Scale Weak Supervision)\"ì´ë¼ëŠ” ë…íŠ¹í•œ ë°©ì‹ì„ ì‚¬ìš©\n",
    "    - WhisperëŠ” ì¸í„°ë„·ì—ì„œ ìˆ˜ì§‘í•œ ë°©ëŒ€í•œ ì–‘ì˜ ì˜¤ë””ì˜¤ì™€ í•´ë‹¹ ì˜¤ë””ì˜¤ì˜ ì „ì‚¬ë³¸ìœ¼ë¡œ í•™ìŠµ\n",
    "    - ì´ ë°ì´í„°ë“¤ì€ ìœ íŠœë¸Œ ì˜ìƒì˜ ìë™ ìƒì„± ìë§‰ì²˜ëŸ¼ ì •í™•ë„ê°€ ì™„ë²½í•˜ì§€ëŠ” ì•Šì§€ë§Œ, ì–‘ì´ ì—„ì²­ë‚˜ê²Œ ë§ë‹¤ëŠ” íŠ¹ì§•ì„ ê°€ì§\n",
    "    - ëŒ€ëŸ‰ì˜ \"ì•½í•œ\" ë°ì´í„°ë¡œ í•™ìŠµí•¨ìœ¼ë¡œì¨, WhisperëŠ” ë‹¤ì–‘í•œ ì–¸ì–´, ë°°ê²½ ì†ŒìŒ, ì–µì–‘ ë“± í˜„ì‹¤ ì„¸ê³„ì˜ ë³µì¡í•œ ìŒì„± í™˜ê²½ì— ëŒ€í•œ ë†’ì€ ì¼ë°˜í™” ëŠ¥ë ¥ì„ ê°–ì¶”ê²Œ ë¨\n",
    "\n",
    "- transcribe : ìŒì„± ì¸ì‹\n",
    "    > model.transcribe(audio, fp16=False)\n",
    "- translate : ë²ˆì—­  \n",
    "    > model.translate(audio, fp16=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYTyJdATEnQ2"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpNGL4AxMa0E"
   },
   "source": [
    "## **ì„¤ì¹˜ ìˆœì„œ(Windows)**\n",
    "\n",
    "1. ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)\n",
    "2. PyTorch ì„¤ì¹˜\n",
    "3. Whisper ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EttpKVxoMzX5"
   },
   "source": [
    "### **1.ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)**\n",
    "í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•œë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ah_OTgncOYCw"
   },
   "outputs": [],
   "source": [
    "python -m venv whisper-env\n",
    "whisper-env\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7zqLLdUPY-7"
   },
   "source": [
    "- **ë§Œì•½ ë³´ì•ˆ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš°(UnauthorizedAccess)**\n",
    "- í•´ê²° ë°©ë²•(ì˜êµ¬í•´ê²°)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDlhyXYaEnQ4"
   },
   "source": [
    "1) VS Code í„°ë¯¸ë„(íŒŒì›Œì…¸)ì—ì„œ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyJDER2BEnQ5"
   },
   "outputs": [],
   "source": [
    "# í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•œë‹¤.\n",
    "Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy RemoteSigned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeMZdkJbEnQ5"
   },
   "source": [
    "2) ìƒˆ í„°ë¯¸ë„ì„ ì—´ê³  ê°€ìƒí™˜ê²½ í™œì„±í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrccFwvNEnQ5"
   },
   "outputs": [],
   "source": [
    "# í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•œë‹¤.\n",
    ".\\whisper-env\\Scripts\\Activate.ps1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_q3gcpR_EnQ5"
   },
   "source": [
    "3) í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OggqmOoEnQ5"
   },
   "outputs": [],
   "source": [
    "# í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰í•œë‹¤.\n",
    "python -c \"import sys; print(sys.executable); print(sys.version)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vt1O4MtgMzff"
   },
   "source": [
    "### **2.PyTorch ì„¤ì¹˜**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tjxo7oBvOD5M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python\\python313\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\python\\python313\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\python\\python313\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\python\\python313\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python\\python313\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\python\\python313\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\python\\python313\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\python\\python313\\lib\\site-packages (from torchvision) (2.3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\python\\python313\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzFX1uv9Mznk"
   },
   "source": [
    "### **3.Whisper ì„¤ì¹˜**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aywVF71vOERd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\user\\appdata\\local\\temp\\pip-req-build-lq51dhdd\n",
      "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: more-itertools in c:\\python\\python313\\lib\\site-packages (from openai-whisper==20250625) (10.8.0)\n",
      "Requirement already satisfied: numba in c:\\python\\python313\\lib\\site-packages (from openai-whisper==20250625) (0.62.0)\n",
      "Requirement already satisfied: numpy in c:\\python\\python313\\lib\\site-packages (from openai-whisper==20250625) (2.3.3)\n",
      "Requirement already satisfied: tiktoken in c:\\python\\python313\\lib\\site-packages (from openai-whisper==20250625) (0.11.0)\n",
      "Requirement already satisfied: torch in c:\\python\\python313\\lib\\site-packages (from openai-whisper==20250625) (2.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\python\\python313\\lib\\site-packages (from openai-whisper==20250625) (4.67.1)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\python\\python313\\lib\\site-packages (from numba->openai-whisper==20250625) (0.45.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\python\\python313\\lib\\site-packages (from tiktoken->openai-whisper==20250625) (2025.9.18)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\python\\python313\\lib\\site-packages (from tiktoken->openai-whisper==20250625) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.8.3)\n",
      "Requirement already satisfied: filelock in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\python\\python313\\lib\\site-packages (from torch->openai-whisper==20250625) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch->openai-whisper==20250625) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python\\python313\\lib\\site-packages (from jinja2->torch->openai-whisper==20250625) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\python\\python313\\lib\\site-packages (from tqdm->openai-whisper==20250625) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\user\\AppData\\Local\\Temp\\pip-req-build-lq51dhdd'\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLykieF9EnQ6"
   },
   "source": [
    "### **4.ffmpeg ì„¤ì¹˜**\n",
    "- ì°¸ê³  : https://angelplayer.tistory.com/351\n",
    "- https://ffmpeg.org/  \n",
    "- ë‹¤ìš´ë¡œë“œ > ìœˆë„ìš° ë²„íŠ¼ >(Windows EXE Files) Windows builds from gyan.dev ì„ íƒ\n",
    "- ffmpeg-git-full.7z ì„ íƒ > ì••ì¶•í’€ê³  > í´ë” ì´ë¦„ì„ ffmpeg ìœ¼ë¡œ ë³€ê²½í•œë‹¤.\n",
    "- ffmpeg í´ë” ì „ì²´ë¥¼ C:\\ë¡œ ì´ë™ì‹œí‚¤ê³ \n",
    "- ê³ ê¸‰ ì‹œìŠ¤í…œ ì„¤ì • > í™˜ê²½ë³€ìˆ˜ > ì‹œìŠ¤í…œ ë³€ìˆ˜ > Pathì— ì¶”ê°€í•œë‹¤. (C:\\ffmpeg\\bin)\n",
    "- ê¼­!!! VSC ì¬ì‹œì‘í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gxVJoTioEnQ6",
    "outputId": "ff8659bd-1dcc-4b65-fbb8-7ebfbd32b2aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ CWD: c:\\python\\ktcloud\\ktcloud_genai\n",
      "â–¶ Audio Path: C:\\python\\ktcloud\\ktcloud_genai\\audio\\ì˜¤ë””ì˜¤-ìŠ¬ë¼ì´ë“œ2.mp3\n",
      "â–¶ Audio Exists?: True\n",
      "â–¶ ffmpeg on PATH?: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "â–¶ ffprobe on PATH?: C:\\ffmpeg\\bin\\ffprobe.EXE\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ì „ ì ê²€ ì½”ë“œ\n",
    "from pathlib import Path\n",
    "import shutil, sys\n",
    "\n",
    "audio = Path(r\"./audio/ì˜¤ë””ì˜¤-ìŠ¬ë¼ì´ë“œ2.mp3\")  # í•„ìš”ì‹œ ì ˆëŒ€ê²½ë¡œë¡œ ë°”ê¾¸ì„¸ìš”\n",
    "print(\"â–¶ CWD:\", Path.cwd())\n",
    "print(\"â–¶ Audio Path:\", audio.resolve())\n",
    "print(\"â–¶ Audio Exists?:\", audio.exists())\n",
    "print(\"â–¶ ffmpeg on PATH?:\", shutil.which(\"ffmpeg\"))\n",
    "print(\"â–¶ ffprobe on PATH?:\", shutil.which(\"ffprobe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPadLTQUEnQ6"
   },
   "outputs": [],
   "source": [
    "# - í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰\n",
    "$env:Path = \"C:\\ffmpeg\\bin;\" + $env:Path\n",
    "ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pKMISxcdEnQ6",
    "outputId": "290cbdc4-2352-419b-f9f5-2d024df27cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\python\\ktcloud\\ktcloud_genai\n",
      "Rel exists?: True\n",
      "Abs exists?: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"Rel exists?:\", Path(\"./audio/ì˜¤ë””ì˜¤-ìŠ¬ë¼ì´ë“œ2.mp3\").exists())\n",
    "print(\"Abs exists?:\", Path(r\"C:\\python\\ktcloud\\ktcloud_genai\\audio\\ì˜¤ë””ì˜¤-ìŠ¬ë¼ì´ë“œ2.mp3\").exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3AetcpfRSd3"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyLeDgtBRTlz"
   },
   "source": [
    "## **Whisperë¡œ ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê¸°**\n",
    "\n",
    "1. Whisper ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "2. ëª¨ë¸ ë¡œë“œí•˜ê¸°\n",
    "3. ìŒì„± íŒŒì¼ì„ ì½ì–´ë“¤ì—¬ ë³€í™˜\n",
    "4. ê²°ê³¼ ì¶œë ¥ ë˜ëŠ” ì €ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbRJiHnbEnQ7"
   },
   "source": [
    "- ì˜ì–´ ì˜¤ë””ì˜¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "2MBQh_HwR5-Z",
    "outputId": "591b45d5-a723-4a7a-969d-33c038e895e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pay attention to me.\n"
     ]
    }
   ],
   "source": [
    "# 1.Whisper ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import whisper\n",
    "\n",
    "# 2.ëª¨ë¸ ë¡œë“œí•˜ê¸°\n",
    "model = whisper.load_model(\"small\")  # tiny, base, small, medium, large\n",
    "\n",
    "# 3.ìŒì„± íŒŒì¼ì„ ì½ì–´ë“¤ì—¬ ë³€í™˜ .wav, .mp3, .m4a, .webm, .ogg, .flac ë“±\n",
    "audio = r\"C:\\python\\ktcloud\\ktcloud_genai\\audio\\ì•„ë™-ì˜ì–´1.wav\"\n",
    "result = model.transcribe(audio, fp16=False)  # fp16=False ì˜µì…˜ì€ CPU í™˜ê²½ì—ì„œ í•„ìš”\n",
    "print(result[\"text\"])\n",
    "\n",
    "\n",
    "# 4.ê²°ê³¼ ì¶œë ¥ ë˜ëŠ” ì €ì¥\n",
    "with open(\"output_eng.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxR68TacEnQ7"
   },
   "source": [
    "- í•œê¸€ ì˜¤ë””ì˜¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NiyhvUZbEnQ7",
    "outputId": "08ce66b3-ae9e-44ee-9378-b026bbe82e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ì»¤í”¼ì˜ ë§›ì„ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” 4ê°€ì§€ ì£¼ìš” ìš”ì†Œë¥¼ ì‚´í´ë³´ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì²«ì§¸, ì‚¼ë¯¸ëŠ” ì‹¬ë§›ì˜ ê°•ë„ë¥¼ ë‚˜íƒ€ë‚´ë©° ì´ëŠ” ê³¼ì¼ì´ë‚˜ ë¡œìŠ¤íŒ… ê³¼ì •ì—ì„œ ê¸°ì¸í•©ë‹ˆë‹¤. ë‘˜ì§¸, ë°”ë””ê°ì€ ì»¤í”¼ê°€ ì… ì•ˆì—ì„œ ëŠê»´ì§€ëŠ” ë¬µì§í•¨ê³¼ ì§ˆê°ì„ ì˜ë¯¸í•˜ë©° ì»¤í”¼ì˜ ë¬´ê²Œê°ì„ í‘œí˜„í•©ë‹ˆë‹¤.\n",
      "ì €ì¥ ì™„ë£Œ: output_kor.txt\n"
     ]
    }
   ],
   "source": [
    "import whisper, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "audio_path = Path(r\"C:\\python\\ktcloud\\ktcloud_genai\\audio\\ì˜¤ë””ì˜¤-ìŠ¬ë¼ì´ë“œ2.mp3\")  # ì ˆëŒ€ê²½ë¡œ ê¶Œì¥\n",
    "\n",
    "\n",
    "# 1) í•„ìˆ˜ ì „ì œ í™•ì¸\n",
    "assert audio_path.exists(), f\"ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {audio_path}\"\n",
    "assert shutil.which(\"ffmpeg\"), \"ffmpegë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ í›„ PATHì— ë“±ë¡í•˜ì„¸ìš”.\"\n",
    "assert shutil.which(\"ffprobe\"), \"ffprobeë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ffmpeg ì„¤ì¹˜ ì‹œ í•¨ê»˜ ë“±ë¡ë©ë‹ˆë‹¤.\"\n",
    "\n",
    "\n",
    "# 2) ëª¨ë¸ ë¡œë“œ (CPU ì‚¬ìš© ì‹œ fp16 ë¹„í™œì„±í™” ê¶Œì¥)\n",
    "model = whisper.load_model(\"small\")   # tiny/base/small/medium/large\n",
    "result = model.transcribe(str(audio_path), fp16=False)  # CPUë©´ fp16=Falseë¡œ ê²½ê³  ì–µì œ\n",
    "print(result[\"text\"])\n",
    "\n",
    "\n",
    "# 3) ì €ì¥\n",
    "Path(\"output_kor.txt\").write_text(result[\"text\"], encoding=\"utf-8\")\n",
    "print(\"ì €ì¥ ì™„ë£Œ: output_kor.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVHXkFjiEnQ7"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL_d48R8Rjq0"
   },
   "source": [
    "## **ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹**\n",
    "\n",
    "- ì°¸ê³  : https://bcuts.tistory.com/197\n",
    "\n",
    "- ë°˜ë³µ ê³¼ì •\n",
    "    - ë§ˆì´í¬ë¡œë¶€í„° 5ì´ˆê°„ ìŒì„±\n",
    "    - ì…ë ¥ ë°ì´í„°ë¥¼ .wav íŒŒì¼ë¡œ ì €ì¥\n",
    "    - ì €ì¥ëœ íŒŒì¼ì„ Whisperë¡œ ì²˜ë¦¬\n",
    "    - í…ìŠ¤íŠ¸ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6J67aq1gEnQ7"
   },
   "source": [
    "### ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tZVhNEJqEnQ7",
    "outputId": "181d8446-9a03-4e71-8e7d-b7198280b22f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\python\\python313\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: numpy in c:\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: soundfile in c:\\python\\python313\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\python\\python313\\lib\\site-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\python\\python313\\lib\\site-packages (from cffi>=1.0->soundfile) (2.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio numpy soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBJXlKdJEnQ8"
   },
   "source": [
    "### ì‹¤ì‹œê°„ ìŒì„±ì¸ì‹ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5FR0RGINEnQ8",
    "outputId": "5f7e0e54-4cbe-4c5c-d668-bd36768d1c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œì‘ (Ctrl+Cë¡œ ì¢…ë£Œ)\n",
      "ğŸ“¢ ì¸ì‹ëœ í…ìŠ¤íŠ¸: \n",
      "ğŸ“¢ ì¸ì‹ëœ í…ìŠ¤íŠ¸:  ì ìˆœì˜ ë¨¹ì€ ë¼ë©´ì€ ë§›ìˆì—ˆë‹¤\n",
      "ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"temp.wav\"\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "stream = audio.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œì‘ (Ctrl+Cë¡œ ì¢…ë£Œ)\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = []\n",
    "        for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "        wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "        wf.close()\n",
    "\n",
    "        result = model.transcribe(WAVE_OUTPUT_FILENAME)\n",
    "        print(\"ğŸ“¢ ì¸ì‹ëœ í…ìŠ¤íŠ¸:\", result[\"text\"])\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mNIgtqgEnQ8"
   },
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
